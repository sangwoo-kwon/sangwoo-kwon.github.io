<!DOCTYPE html>
<html lang="en">
<!-- Template: https://github.com/luost26/academic-homepage -->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Publications - Sangwoo Kwon</title>

    <!-- Stylesheets -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.6.0/css/bootstrap.min.css" integrity="sha512-P5MgMn1jBN01asBgU0z60Qk4QxiXo86+wlFahKrsQf37c9cro517WzVSPPV1tDKzhku2iJ2FVgL67wG03SGnNA==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin="anonymous" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;0,900;1,300;1,400;1,700;1,900&family=Fira+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/global.css">
</head>
<body class="bg-light" data-spy="scroll" data-target="#navbar-year" data-offset="100">
    <!-- <nav class="navbar navbar-expand-sm navbar-dark bg-dark fixed-top mb-5 shadow-sm">
    <div class="container-lg">
        <a class="navbar-brand"><strong>Sangwoo Kwon</strong></a>
        <button class="navbar-toggler" style="font-size: 1em; padding: 0.5em;" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fas fa-map"></i> Menu
        </button>

        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="/">Home</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>
 -->
    <div class="container-lg">
        

<div class="row">
    <div class="col-12 col-lg-10">
        
        
        <h2 class="pt-4" id="year-2024">2024</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-xl">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-5 col-xl-4 mb-md-0 p-md-3 align-items-center d-flex"><img data-src="/assets/images/covers/2025/dpllm.png" alt="DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment" class="lazy w-100 rounded-sm align-middle" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-7 col-xl-8 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            <strong>Sangwoo Kwon</strong>, </span><span class="text-body">
            Seong Hoon Seo, </span><span class="text-body">
            Jae W. Lee, </span><span class="text-body">
            Yeonhong Park</span></p>
            <p class="mt-0 mb-0 small"><i>39th Annual Conference on Neural Information Processing Systems (NeurIPS)</i>, 2025  <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted">A novel mechanism that dynamically assigns precision to each layer based on input values. DP-LLM augments each linear layer in an LLM with a precision selector that determines the bitwidth at runtime using a lightweight error estimator and threshold values learned through fine-tuning.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2508.06041">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>



<div class="row no-gutters d-md-none border-bottom border-gray rounded-xl-top " data-src="">
    <div class="w-100 rounded-xl-top " style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div class="m-4"><img data-src="/assets/images/covers/2025/dpllm.png" alt="DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            <strong>Sangwoo Kwon</strong>, </span><span class="text-body">
            Seong Hoon Seo, </span><span class="text-body">
            Jae W. Lee, </span><span class="text-body">
            Yeonhong Park</span></p>
                <p class="mt-0 mb-0 small"><i>39th Annual Conference on Neural Information Processing Systems (NeurIPS)</i>, 2025  <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted">A novel mechanism that dynamically assigns precision to each layer based on input values. DP-LLM augments each linear layer in an LLM with a precision selector that determines the bitwidth at runtime using a lightweight error estimator and threshold values learned through fine-tuning.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2508.06041">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-5 col-xl-4 mb-md-0 p-md-3 align-items-center d-flex"><img data-src="/assets/images/covers/2025/kvzip.png" alt="KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction" class="lazy w-100 rounded-sm align-middle" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-7 col-xl-8 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Jang-Hyun Kim, </span><span class="text-body">
            Jinuk Kim, </span><span class="text-body">
            <strong>Sangwoo Kwon</strong>, </span><span class="text-body">
            Jae W. Lee, </span><span class="text-body">
            Sangdoo Yun, </span><span class="text-body">
            Hyun Oh Song</span></p>
            <p class="mt-0 mb-0 small"><i>39th Annual Conference on Neural Information Processing Systems (NeurIPS)</i>, 2025  <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted">A query-agnostic KV cache eviction method enabling effective reuse of compressed KV caches across diverse queries. KVzip quantifies the importance of a KV pair using the underlying LLM to reconstruct original contexts from cached KV pairs, subsequently evicting pairs with lower importance.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2505.23416">[paper]</a>
                
                
            </p>

        </div>
    </div>
</div>



<div class="row no-gutters d-md-none  border-gray  rounded-xl-bottom" data-src="">
    <div class="w-100  rounded-xl-bottom" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div class="m-4"><img data-src="/assets/images/covers/2025/kvzip.png" alt="KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Jang-Hyun Kim, </span><span class="text-body">
            Jinuk Kim, </span><span class="text-body">
            <strong>Sangwoo Kwon</strong>, </span><span class="text-body">
            Jae W. Lee, </span><span class="text-body">
            Sangdoo Yun, </span><span class="text-body">
            Hyun Oh Song</span></p>
                <p class="mt-0 mb-0 small"><i>39th Annual Conference on Neural Information Processing Systems (NeurIPS)</i>, 2025  <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted">A query-agnostic KV cache eviction method enabling effective reuse of compressed KV caches across diverse queries. KVzip quantifies the importance of a KV pair using the underlying LLM to reconstruct original contexts from cached KV pairs, subsequently evicting pairs with lower importance.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2505.23416">[paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2022">2022</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-xl">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-5 col-xl-4 mb-md-0 p-md-3 align-items-center d-flex"><img data-src="/assets/images/covers/2022/40nm.png" alt="A 40nm 5.6TOPS/W 239GOPS/mm² Self-Attention Processor with Sign Random Projection-based Approximation" class="lazy w-100 rounded-sm align-middle" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-7 col-xl-8 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">A 40nm 5.6TOPS/W 239GOPS/mm² Self-Attention Processor with Sign Random Projection-based Approximation</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Seong Hoon Seo*, </span><span class="text-body">
            Soosung Kim*, </span><span class="text-body">
            Sung Jun Jung, </span><span class="text-body">
            <strong>Sangwoo Kwon</strong>, </span><span class="text-body">
            Hyunseung Lee, </span><span class="text-body">
            Jae W. Lee</span>
<!-- <mark>(* <i> equal contribution</i>)</mark> --><br>(* <i> equal contribution)</i></p>
            <p class="mt-0 mb-0 small"><i>48th European Solid-State Circuits Conference (ESSCIRC)</i>, 2022  <span data-semantic-scholar-id=""></span></p>
            <p class="mt-0 mb-0 small text-muted">A novel self-attention accelerator that skips most of the computation by utilizing an approximate candidate selection algorithm. Implemented in a 40nm CMOS technology, the 5.64 mm² chip operates at 100-600 MHz consuming 48.3-685 mW to achieve the energy and area efficiency of 0.354-5.61 TOPS/W and 239 GOPS/mm2, respectively.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9911343">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>



<div class="row no-gutters d-md-none  border-gray rounded-xl-top rounded-xl-bottom" data-src="">
    <div class="w-100 rounded-xl-top rounded-xl-bottom" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div class="m-4"><img data-src="/assets/images/covers/2022/40nm.png" alt="A 40nm 5.6TOPS/W 239GOPS/mm² Self-Attention Processor with Sign Random Projection-based Approximation" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">A 40nm 5.6TOPS/W 239GOPS/mm² Self-Attention Processor with Sign Random Projection-based Approximation</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Seong Hoon Seo*, </span><span class="text-body">
            Soosung Kim*, </span><span class="text-body">
            Sung Jun Jung, </span><span class="text-body">
            <strong>Sangwoo Kwon</strong>, </span><span class="text-body">
            Hyunseung Lee, </span><span class="text-body">
            Jae W. Lee</span>
<!-- <mark>(* <i> equal contribution</i>)</mark> --><br>(* <i> equal contribution)</i></p>
                <p class="mt-0 mb-0 small"><i>48th European Solid-State Circuits Conference (ESSCIRC)</i>, 2022  <span data-semantic-scholar-id=""></span></p>
                <p class="mt-0 mb-0 small text-muted">A novel self-attention accelerator that skips most of the computation by utilizing an approximate candidate selection algorithm. Implemented in a 40nm CMOS technology, the 5.64 mm² chip operates at 100-600 MHz consuming 48.3-685 mW to achieve the energy and area efficiency of 0.354-5.61 TOPS/W and 239 GOPS/mm2, respectively.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9911343">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
    </div>

    <div class="col-2 d-none d-lg-block">
        <div id="navbar-year" class="nav nav-pills flex-column sticky-top" style="top: 80px">
            
            <a class="nav-link d-block" href="#year-2024">2024</a>
            
            <a class="nav-link d-block" href="#year-2022">2022</a>
            
        </div>
    </div>

</div>

    </div>
    <footer class="footer border-top py-2 mt-5 bg-white small">
    <div class="container-lg">
        <div class="row my-3">
            <div class="col-6">
                <div class="text-muted">
                    <i>Last updated: Oct 2025</i>
                </div>
            </div>
            <div class="col-6">
                <div class="text-right text-muted">
                    <a href="https://github.com/luost26/academic-homepage" target="_blank"><i class="fas fa-pencil-ruler"></i> academic-homepage</a>
                </div>
            </div>
        </div>
    </div>
</footer>


    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery.lazy/1.7.9/jquery.lazy.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.6.0/js/bootstrap.min.js" integrity="sha512-XKa9Hemdy1Ui3KSGgJdgMyYlUg1gM+QhL6cnlyTe2qzMCYm4nAZ1PsVerQzTTXzonUR+dmswHqgJPuwCq1MaAg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/github-buttons/2.14.2/buttons.min.js" integrity="sha512-OYwZx04hKFeFNYrWxIyo3atgGpb+cxU0ENWBZs72X7T9U+NoHPM1ftUn/Mfw7dRDXrqWA6M1wBg6z6fGE32aeA==" crossorigin="anonymous"></script>
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
    <script src="https://unpkg.com/imagesloaded@5/imagesloaded.pkgd.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
              delimiters: [
                  {left: '$$', right: '$$', display: true},
                  {left: '$', right: '$', display: false}
              ],
              throwOnError : false
            });
        });
    </script>
    <script src="/assets/js/common.js"></script>
    <script src="/assets/js/bubble_visual_hash.js"></script>
    <script src="/assets/js/semantic_scholar_citation_count.js"></script>
</body>
</html>
